{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex optimization\n",
    "\n",
    "So far we've been thinking about reformulations of into mixed-integer linear optimization problems of the form\n",
    "\n",
    "\\begin{align}\n",
    "\\min \\quad&f(x)\\\\\n",
    "\\text{s.t.} \\quad& g(x) = 0, \\\\\n",
    "& h(x) \\leq 0.\n",
    "\\end{align}\n",
    "where the functions $f$ and $g$ and $h$ are affine/linear.\n",
    "\n",
    "A special class of nonlinear optimization problems are *convex* optimization problems where $f$ and $h$ are convex and $g$ is affine. Under some additional regularity assumptions, much of the duality theory from linear programming can be extended to convex optimization, and there exist efficient (polynomial-time) algorithms to solve these problems. With few exceptions, if your problem is convex, you can expect to be able to solve it efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting convexity\n",
    "\n",
    "A function $f: \\mathbb{R}^n \\to \\mathbb{R}$ is convex iff $f(\\theta x + (1-\\theta)y) \\leq \\theta f(x) + (1-\\theta)f(y), \\forall x,y \\in \\mathbb{R}^n \\text{ and } \\theta \\in [0,1]$.\n",
    "\n",
    "Given an arbitrary function $f$, detecting if $f$ is convex is [NP-Hard](http://web.mit.edu/~a_a_a/Public/Publications/convexity_nphard.pdf). So how do we know if a problem is convex?\n",
    "\n",
    "A reasonable approach is to make sure that a model is built-up in a manner that lets us prove convexity by using a calculus of convex analysis; this is  **Disciplined Convex Programming** (DCP).\n",
    "\n",
    "We start with operations that are known to be convex:\n",
    "- Norms (why?)\n",
    "- $\\exp(\\cdot)$\n",
    "- $-\\log(\\cdot)$\n",
    "- $x^p$ for $p \\geq 1$ and $x \\geq 0$.\n",
    "- $1/x$ for $x > 0$\n",
    "- $x^2$\n",
    "- ...\n",
    "\n",
    "Then add composition rules, e.g., $f(g(\\cdot))$ is convex when $f$ is convex and\n",
    "- $g$ is linear or affine\n",
    "- $f$ is monotonic increasing and $g$ is convex\n",
    "\n",
    "Also, $f_1+f_2$ and $\\max\\{f_1,f_2\\}$ are convex when $f_1$ and $f_2$ are convex.\n",
    "\n",
    "So our previous example of $x^2 - \\log(x)$ is convex by these rules, because it is the sum of convex functions. So is $\\max\\{e^x,1/x\\}$ ([plot](http://www.wolframalpha.com/input/?i=max%28exp%28x%29%2C1%2Fx%29+for+x+%3E+0)).\n",
    "\n",
    "Note that these rules are *sufficient* but not *necessary* to prove convexity. \n",
    "\n",
    "There are a lot of existing materials on DCP which we won't try to reproduce here. Let's head over to http://dcp.stanford.edu/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**\\[Exercise\\]**: DCP Quiz\n",
    "\n",
    "> Play the [DCP quiz](http://dcp.stanford.edu/quiz). Turn up the difficulty to hard for extra fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving \"DCP-compliant\" problems\n",
    "\n",
    "DCP rules are useful not just for proving convexity, but also for *solving* the problems.\n",
    "\n",
    "For example, we (should) know that the following problem\n",
    "\\begin{align}\n",
    "\\min \\quad& {||}x||_1\\\\\n",
    "\\text{s.t.} \\quad& Ax = b, \\\\\n",
    "& x \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "where $||x||_1 = \\sum_i |x_i|$ can be solved by using linear programming.\n",
    "\n",
    "Just introduce auxiliary variables $z$ and solve\n",
    "\\begin{align}\n",
    "\\min \\quad& \\sum_i z_i\\\\\n",
    "\\text{s.t.} \\quad&z_i \\geq x_i, \\forall i\\\\\n",
    "& z_i \\geq -x_i, \\forall i\\\\\n",
    "& Ax = b, \\\\\n",
    "& x \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "Similarly\n",
    "\\begin{align}\n",
    "\\min \\quad& {||}x||_\\infty\\\\\n",
    "\\text{s.t.} \\quad& Ax = b, \\\\\n",
    "& x \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "where $||x||_\\infty = \\max\\{|x_1|,\\cdots,|x_n|\\}$ can be formulated as\n",
    "\n",
    "\\begin{align}\n",
    "\\min \\quad& z\\\\\n",
    "\\text{s.t.} \\quad&z \\geq x_i, \\forall i\\\\\n",
    "& z \\geq -x_i, \\forall i\\\\\n",
    "& Ax = b, \\\\\n",
    "& x \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "(What do we do when $||\\cdot||_1$ and $||\\cdot||_\\infty$ appear in convex constraints?)\n",
    "\n",
    "Given these results, we might say that $||\\cdot||_1$ and $||\\cdot||_\\infty$ are *LP-representable*, in a sense that can be made rigorous.\n",
    "\n",
    "What about $||\\cdot||_2$? It's SOCP (second-order conic programming) representable, since\n",
    "$$\n",
    "||x||_2 \\leq t\n",
    "$$\n",
    "is precisely a second-order conic constraint that's already supported by Gurobi, CPLEX, MOSEK, ECOS, SCS, ...\n",
    "\n",
    "What about $1/x$? It's also SOCP representable since\n",
    "$$\n",
    "1/x \\leq t\n",
    "$$\n",
    "iff\n",
    "$$\n",
    "||(2,x-t)||_2 \\leq x+t.\n",
    "$$\n",
    "\n",
    "It turns out that [A LOT](http://docs.mosek.com/generic/modeling-letter.pdf) of common convex functions are SOCP-representable.\n",
    "\n",
    "Once we know how to represent basic operations using LPs or SOCPs, we can easily compose them. For example, we would represent\n",
    "\n",
    "\\begin{align}\n",
    "\\min \\quad& \\max\\{||Cx-d||,1/x_1\\}\\\\\n",
    "\\text{s.t.} \\quad& Ax = b, \\\\\n",
    "& x \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "as\n",
    "\n",
    "\\begin{align}\n",
    "\\min \\quad& t\\\\\n",
    "\\text{s.t.} \\quad& t \\geq z_1 \\\\\n",
    "&t \\geq z_2\\\\\n",
    "&{||}Cx-d|| \\leq z_1\\\\\n",
    "&{||}(2,x_1-z_2)|| \\leq x_1+z_2\\\\\n",
    "& Ax = b, \\\\\n",
    "& x \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "and hand the problem off to Gurobi as an SOCP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCP in summary\n",
    "\n",
    "- Represent the model in a way that makes it easy to use DCP rules to prove convexity.\n",
    "- Break down the individual pieces into parts that are representable using LP, SOCP, semidefinite programming, (or exponential cones)\n",
    "- Use composition rules to *automatically* generate a complete formulation that can be given to existing solvers\n",
    "- Note that derivatives aren't used anywhere!\n",
    "\n",
    "The first implementation of DCP was [CVX](http://cvxr.com/cvx/) in MATLAB. More recently, it's been implemented in [cvxpy](https://github.com/cvxgrp/cvxpy) and [Convex.jl](https://github.com/JuliaOpt/Convex.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick convex prototyping\n",
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scalar variable\n",
    "x = Variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Column) vector variable\n",
    "y = Variable(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matrix variable\n",
    "Z = Variable(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions\n",
    "Convex.jl allows you to use a [wide variety of functions](http://convexjl.readthedocs.org/en/latest/operations.html) on variables and on expressions to form new expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x + 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = y[1] + logdet(Z) + sqrt(x) + minimum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the expression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.children[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "\n",
    "A constraint is convex if convex combinations of feasible points are also feasible. Equivalently, feasible sets are convex sets.\n",
    "\n",
    "In other words, convex constraints are of the form\n",
    "\n",
    "* `convexExpr <= 0`\n",
    "* `concaveExpr >= 0`\n",
    "* `affineExpr == 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x^2 <= sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = Z \n",
    "for i = 1:length(y)\n",
    "    M += rand(size(Z))*y[i]\n",
    "end\n",
    "M âª° 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable()\n",
    "y = Variable(4)\n",
    "objective = 2*x + 1 - sqrt(sum(y))\n",
    "constraint = x >= maximum(y)\n",
    "p = minimize(objective, constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# solve the problem\n",
    "solve!(p)\n",
    "p.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can evaluate expressions directly\n",
    "evaluate(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 1: Elastic Net Regularization\n",
    "\n",
    "Taken from https://github.com/JuliaOpt/Convex.jl/blob/master/examples/Convex.jl_intro_ISMP2015.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the Convex.jl module available\n",
    "using Convex\n",
    "using SCS # first order splitting conic solver [O'Donoghue et al., 2014]\n",
    "set_default_solver(SCSSolver(verbose=0)) # could also use Gurobi, Mosek, CPLEX, ...\n",
    "\n",
    "# Generate random problem data\n",
    "m = 50;  n = 100\n",
    "A = randn(m, n)\n",
    "xâ® = sprand(n, 1, .5) # true (sparse nonnegative) parameter vector\n",
    "noise = .1*randn(m)    # gaussian noise\n",
    "b = A*xâ® + noise      # noisy linear observations\n",
    "\n",
    "# Create a (column vector) variable of size n.\n",
    "x = Variable(n)\n",
    "\n",
    "# nonnegative elastic net with regularization\n",
    "Î» = 1\n",
    "Î¼ = 1\n",
    "problem = minimize(norm(A * x - b)^2 + Î»*norm(x)^2 + Î¼*norm(x, 1), \n",
    "                   x >= 0)\n",
    "\n",
    "# Solve the problem by calling solve!\n",
    "solve!(problem)\n",
    "\n",
    "println(\"problem status is \", problem.status) # :Optimal, :Infeasible, :Unbounded etc.\n",
    "println(\"optimal value is \", problem.optval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 2: Support Vector Machines (SVM)\n",
    "\n",
    "[Support vector machines](http://en.wikipedia.org/wiki/Support_vector_machine) are a popular model in machine learning for classification. We'll use this example to illustrate the basic use of Convex.jl.\n",
    "\n",
    "The basic problem is that we are given a set of N points $x_1,x_2,\\ldots, x_N \\in \\mathbb{R}^n$ and labels $y_1, y_2, \\ldots y_n \\in \\{-1,+1\\}$. And we want to find a hyperplane of the form $w^Tx-b = 0$ that *separates* the two classes, i.e. $w^Tx_i - b \\geq 1$ when $y_i = +1$ and $w^Tx_i - b \\leq -1$ when $y_i = -1$. This condition can be written as $y_i(w^Tx_i - b) \\geq 1, \\forall\\, i$.\n",
    "\n",
    "Such a hyperplane will not exist in general if the data overlap, so instead we'll just try to minimize violations of the constraint $y_i(w^Tx_i - b) \\geq 1, \\forall\\, i$ by adding a penalty when it is violated. The optimization problem can be stated as\n",
    "$$\n",
    "\\min_{w,b} \\sum_{i=1}^N \\left[\\max\\{0, 1 - y_i(w^Tx_i - b)\\}\\right] + \\gamma ||w||_2^2\n",
    "$$\n",
    "Note that we penalize the norm of $w$ in order to guarantee a unique solution.\n",
    "\n",
    "Now let's write our own SVM solver!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using PyPlot\n",
    "using Convex\n",
    "using ECOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to generate some random test data\n",
    "function gen_data(N)\n",
    "    # for +1 data, symmetric multivariate normal with center at (1,2)\n",
    "    pos = rand(MvNormal([1.0,2.0],1.0),N)\n",
    "    # for -1 data, symmetric multivariate normal with center at (-1,1)\n",
    "    neg = rand(MvNormal([-1.0,1.0],1.0),N)\n",
    "    x = [pos neg]\n",
    "    y = [fill(+1,N),fill(-1,N)]\n",
    "    return x,y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y = gen_data(100)\n",
    "plot(x[1,1:100], x[2,1:100], \"ro\", x[1,101:200], x[2,101:200], \"bo\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we translate the optimization problem into Convex.jl form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "const Î³ = 0.005\n",
    "function svm_convex(x,y)\n",
    "    n = size(x,1) # problem dimension\n",
    "    N = size(x,2) # number of points\n",
    "    w = Variable(n)\n",
    "    b = Variable()\n",
    "    \n",
    "    problem = minimize( Î³*sum_squares(w) + sum(max(1-y.*(x'*w-b),0)))\n",
    "    solve!(problem, ECOSSolver())\n",
    "    return evaluate(w), evaluate(b)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "x,y = gen_data(N)\n",
    "\n",
    "plot(x[1,1:N], x[2,1:N], \"ro\", x[1,(N+1):2N], x[2,(N+1):2N], \"bo\");\n",
    "w,b = svm_convex(x,y)\n",
    "\n",
    "@show w,b\n",
    "\n",
    "xmin, xmax = xlim()\n",
    "ymin, ymax = ylim()\n",
    "y1 = (1+b-w[1]*xmin)/w[2]\n",
    "y2 = (1+b-w[1]*xmax)/w[2]\n",
    "plot([xmin,xmax], [y1,y2], \"k-\");\n",
    "y1 = (-1+b-w[1]*xmin)/w[2]\n",
    "y2 = (-1+b-w[1]*xmax)/w[2]\n",
    "plot([xmin,xmax], [y1,y2], \"k-\");\n",
    "y1 = (b-w[1]*xmin)/w[2]\n",
    "y2 = (b-w[1]*xmax)/w[2]\n",
    "ylim(ymin,ymax)\n",
    "plot([xmin,xmax], [y1,y2], \"k-\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**\\[Exercise\\]**: Sensitivity\n",
    "\n",
    "> Increase the separation between the positive and negative data by modifying the means in ``gen_data``. How does the solution change?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**\\[Exercise\\]**: JuMP version\n",
    "\n",
    "> Translate the Convex.jl model into a JuMP model with linear constraints and a quadratic objective. For example, ``sum_squares(w)`` becomes ``sum{w[i]^2,i=1:n}``. Hint: the formulation is given on Wikpedia. (You may want to use ``IpoptSolver`` since ``ECOSSolver`` supports second-order conic constraints but won't directly accept quadratic objectives.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "- Convex.jl vs. JuMP\n",
    "- Derivative-based nonlinear vs. automatic transformation to LP/SOCP/conic form"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
